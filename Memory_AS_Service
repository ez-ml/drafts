Overview
This document outlines the design for developing "Memory as a Service" (MaaS) for customer support chatbots, implemented in GoLang and leveraging DynamoDB as the backend. The service will cater to various memory requirements, such as chat message history, conversation summaries, knowledge graphs, token buffers, agent states, and entity memory. A Python client SDK will be provided for easy integration with consumer applications.


DynamoDB Schemas
    Table Structure
        Table Name: <namespace>_sessions
            Partition Key: session_id (string) - Unique identifier for each session.
            Sort Key: item_type#timestamp (string) - Combination of item type and timestamp to distinguish between different types of data.
         
        Attributes:
            session_id (string) - Unique identifier for each session.
            item_type (string) - Type of the item (e.g., user_message, ai_response, summary, knowledge_graph, agent_state, entity).
            timestamp (number) - Timestamp of the item.
            data (string) - JSON string containing the actual data.
            ttl (number) - Time-to-live attribute for automatic expiration.

Examples 
{
  "session_id": "12345",
  "item_type#timestamp": "message#1617171717",
  "data": "{\"user_id\":\"user1\",\"message\":\"Hello, how can I help you?\"}",
  "ttl": 1619773717
}

{
  "session_id": "12345",
  "item_type#timestamp": "agent_state#1617171717",
  "data": "{\"state\":\"active\"}",
  "ttl": 1619773717
}

{
  "session_id": "12345",
  "item_type#timestamp": "entity#1617171717",
  "data": "{\"entity_id\":\"entity1\",\"attributes\":{\"attr1\":\"value1\"}}",
  "ttl": 1619773717
}



API Endpoints
    POST /session/init: Initialize a session.
    PUT /session/update: Update an existing session.
        Request Body:
        {
          "session_id": "12345",
          "item_type": "user_message",
          "timestamp": 1617171717,
          "data": "{\"message\":\"Hello, how can I help you?\"}",
          "ttl": 1619773717
        }
SDK Functions
    def init_session(self, session_id=None):
        ......
    def update_session
    def get_conversation_history(limit=None)
    def get_last_k_user_messages
    def get_last_k_system_responses
    def get_summary
    def get_knowledge_graph
====

[
  {
    "SessionID": "session1",
    "Timestamp": 1622548800,
    "MessageType": "UserQuestion",
    "MessageContent": "What is the weather like today?",
    "UserID": "user1",
    "AIResponseID": "response1"
  },
  {
    "SessionID": "session1",
    "Timestamp": 1622548810,
    "MessageType": "AIResponse",
    "MessageContent": "The weather is sunny with a high of 75 degrees.",
    "UserID": "user1",
    "AIResponseID": "response1"
  },
  {
    "SessionID": "session1",
    "Timestamp": 1622548820,
    "MessageType": "UserQuestion",
    "MessageContent": "Will it rain tomorrow?",
    "UserID": "user1",
    "AIResponseID": "response2"
  },
  {
    "SessionID": "session1",
    "Timestamp": 1622548830,
    "MessageType": "AIResponse",
    "MessageContent": "No, it will not rain tomorrow.",
    "UserID": "user1",
    "AIResponseID": "response2"
  },
  {
    "SessionID": "session2",
    "Timestamp": 1622635200,
    "MessageType": "UserQuestion",
    "MessageContent": "What is the capital of France?",
    "UserID": "user2",
    "AIResponseID": "response3"
  },
  {
    "SessionID": "session2",
    "Timestamp": 1622635210,
    "MessageType": "AIResponse",
    "MessageContent": "The capital of France is Paris.",
    "UserID": "user2",
    "AIResponseID": "response3"
  }
]



---

Problem Statement
The advent of conversational AI has revolutionized customer support by enabling automated, efficient, and scalable interaction with customers. However, building a robust and effective conversational chatbot for customer support presents several challenges, especially when dealing with complex, multi-turn, and multi-pass conversations. The critical components necessary for such a system include capturing conversation history, generating summaries, maintaining knowledge graphs, tracking agent workflow states, and managing a semantic cache with vector representations. These components must work together seamlessly to support real-time, low-latency interactions and ensure accurate and contextually relevant responses.

Key Challenges
Conversation History Management:

Problem: Efficiently capturing and storing the conversation history for each session is crucial for maintaining context in multi-turn conversations.
Requirement: The system must support low-latency retrieval of conversation history, allowing the chatbot to reference previous interactions within a session quickly.
Summary Generation:

Problem: Summarizing conversations to provide a quick overview of the interaction is essential for both the chatbot and human agents.
Requirement: The system should generate accurate and concise summaries in real-time, enabling quick understanding of the conversation's context and progress.
Knowledge Graph Integration:

Problem: Maintaining an up-to-date knowledge graph that can be queried to provide relevant information during conversations is critical for addressing customer queries effectively.
Requirement: The system must seamlessly integrate with a dynamic knowledge graph, supporting real-time updates and queries.
Agent Workflow States Tracking:

Problem: In scenarios where human agents are involved, tracking the workflow states of agents is necessary to manage the transition between chatbot and human support.
Requirement: The system should capture and manage agent workflow states, ensuring smooth handoffs and continuity in the conversation.
Semantic Cache with Vector Representations:

Problem: Storing and retrieving semantically relevant information using vector representations is essential for understanding and responding to user queries accurately.
Requirement: The system must support a semantic cache that allows for quick vector-based searches, enhancing the chatbotâ€™s ability to provide contextually relevant responses.
Retrieval-Augmented Generation (RAG) Workflow:

Problem: Implementing a RAG-based workflow to support multi-turn, multi-pass conversations is challenging due to the need for integrating retrieval mechanisms with generative models.
Requirement: The system must support a hybrid workflow where relevant information is retrieved and combined with generative models to produce accurate and context-aware responses.
Objectives
To address these challenges, we propose developing a comprehensive service called Memory as a Service. This service will provide the following features via low-latency APIs:

Conversation History API: Captures and retrieves the complete history of interactions within a session.
Summary API: Generates real-time summaries of conversations.
Knowledge Graph API: Integrates with a knowledge graph to fetch and update relevant information dynamically.
Agent Workflow API: Tracks and manages the states of human agents involved in the conversation.
Semantic Cache API: Manages vector-based semantic cache for efficient storage and retrieval of contextually relevant information.
RAG Workflow API: Implements a hybrid retrieval-augmented generation workflow to support multi-turn, multi-pass conversations.
By providing these features, Memory as a Service aims to enhance the capabilities of the conversational chatbot, ensuring efficient, accurate, and context-aware customer support interactions.

SELECT * FROM ChatHistory WHERE SessionID = 'session1'
SELECT * FROM ChatHistory.SessionID-MessageType-Index WHERE SessionID = 'session1' AND MessageType = 'UserQuestion'
SELECT * FROM ChatHistory.UserID-Timestamp-Index WHERE UserID = 'user1' AND Timestamp BETWEEN 1593600000 AND 1625133600

